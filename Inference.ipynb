{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from skimage import io, transform\n",
    "from skimage.transform import resize\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function reads in a .dcm file, checks the important fields for our device, and returns a numpy array\n",
    "# of just the imaging data\n",
    "def check_dicom(filename): \n",
    "    # todo\n",
    "    \n",
    "    print('Load file {} ...'.format(filename))\n",
    "    ds = pydicom.dcmread(filename)       \n",
    "    \n",
    "    if ds.Modality != 'DX' or ds.PatientPosition not in ['AP', 'PA'] or ds.BodyPartExamined != 'CHEST':\n",
    "        print('DICOM file not usable for this method')\n",
    "        return\n",
    "    else:\n",
    "        print('DICOM file is correct for this method')\n",
    "        img = ds.pixel_array\n",
    "        return img\n",
    "    \n",
    "    \n",
    "# This function takes the numpy array output by check_dicom and \n",
    "# runs the appropriate pre-processing needed for our model input\n",
    "def preprocess_image(img,img_mean,img_std,img_size): \n",
    "    \n",
    "    img = img/255\n",
    "    proc_img = transform.resize((img - img.mean())/img.std(), img_size)\n",
    "  \n",
    "    return proc_img\n",
    "\n",
    "# This function loads in our trained model w/ weights and compiles it \n",
    "def load_model(model_path, weight_path):\n",
    "    # todo\n",
    "\n",
    "    with open(model_path, 'r') as json_file:\n",
    "        json_savedModel= json_file.read()\n",
    "    \n",
    "    model = tf.keras.models.model_from_json(json_savedModel)\n",
    "    model.summary()    \n",
    "    \n",
    "    model.load_weights(weight_path)   \n",
    "    \n",
    "    optimizer = Adam(lr=1e-5)\n",
    "    loss = 'binary_crossentropy'\n",
    "    metrics = ['binary_accuracy']    \n",
    "    \n",
    "    model.compile(optimizer='Adam', loss=loss, metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# This function uses our device's threshold parameters to predict whether or not\n",
    "# the image shows the presence of pneumonia using our trained model\n",
    "def predict_image(model, img, thresh): \n",
    "    # todo    \n",
    "    \n",
    "    prediction = model.predict(img)\n",
    "    \n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              25691136  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 41,062,209\n",
      "Trainable params: 26,347,521\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Load file test1.dcm ...\n",
      "DICOM file is correct for this method\n",
      "[[0.74040437]]\n",
      "Load file test2.dcm ...\n",
      "DICOM file is correct for this method\n",
      "[[0.74340117]]\n",
      "Load file test3.dcm ...\n",
      "DICOM file is correct for this method\n",
      "[[0.6929998]]\n",
      "Load file test4.dcm ...\n",
      "DICOM file not usable for this method\n",
      "Load file test5.dcm ...\n",
      "DICOM file not usable for this method\n",
      "Load file test6.dcm ...\n",
      "DICOM file not usable for this method\n"
     ]
    }
   ],
   "source": [
    "test_dicoms = ['test1.dcm','test2.dcm','test3.dcm','test4.dcm','test5.dcm','test6.dcm']\n",
    "\n",
    "model_path = 'my_modelBARA.json' #path to saved model\n",
    "weight_path = 'xray_class_my_model.bestBARA' #path to saved best weights\n",
    "\n",
    "IMG_SIZE=(1,224,224,3) # This might be different if you did not use vgg16\n",
    "img_mean = -5.998623e-06 # loads the mean image value they used during training preprocessing\n",
    "img_std = 0.9999994 # loads the std dev image value they used during training preprocessing\n",
    "\n",
    "my_model = load_model(model_path, weight_path) #loads model\n",
    "thresh = .9 #loads the threshold they chose for model classification \n",
    "\n",
    "# use the .dcm files to test your prediction\n",
    "for i in test_dicoms:\n",
    "    \n",
    "    img = np.array([])\n",
    "    img = check_dicom(i)\n",
    "    \n",
    "    if img is None:\n",
    "        continue\n",
    "        \n",
    "    img_proc = preprocess_image(img,img_mean,img_std,IMG_SIZE)\n",
    "    pred = predict_image(my_model,img_proc,thresh)\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
